{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "kZycVI0HWqUY"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from geopy.geocoders import Nominatim\n",
    "from translate import Translator\n",
    "import seaborn as sns\n",
    "from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\Solar\\\\Furiends\\\\Furiends\\\\data\\\\raw\\\\Fake Data2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bigT.sql',\n",
       " 'bigT2.csv',\n",
       " 'bigT3.csv',\n",
       " 'data_with_satisfication.csv',\n",
       " 'freq&dura per user per act_category.sql',\n",
       " 'frequency&duration_activity.csv',\n",
       " 'fulldb-09-03-2023-23-04-beta.sql',\n",
       " 'whole11.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all the files in the data folder; \n",
    "os.listdir(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Rehabilitation</th>\n",
       "      <th>Pet_intimacy</th>\n",
       "      <th>category_name</th>\n",
       "      <th>Pet_Name</th>\n",
       "      <th>log_count</th>\n",
       "      <th>com_count</th>\n",
       "      <th>avg_loading</th>\n",
       "      <th>sum_duration</th>\n",
       "      <th>User_satisfication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Bruen</td>\n",
       "      <td>5272 Adela Overpass Suite 982\\r\\nRozellacheste...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.42</td>\n",
       "      <td>'Maltese'</td>\n",
       "      <td>Barney</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.268787</td>\n",
       "      <td>3.522098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eliseo</td>\n",
       "      <td>Trantow</td>\n",
       "      <td>2506 Mertz Inlet\\r\\nSouth Ezekielshire, OK 56215</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>'Golden Retriever'</td>\n",
       "      <td>Juliana</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>3.717647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oceane</td>\n",
       "      <td>Walter</td>\n",
       "      <td>9469 Frank Orchard Apt. 685\\r\\nLake Irmastad, ...</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91</td>\n",
       "      <td>'Bulldog'</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.526618</td>\n",
       "      <td>0.225447</td>\n",
       "      <td>4.005074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Zack</td>\n",
       "      <td>Marvin</td>\n",
       "      <td>982 Susan Manors\\r\\nPort Amiya, UT 97043-2723</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>'German Shepherd'</td>\n",
       "      <td>Yasmine</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.550415</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>9.152728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Marco</td>\n",
       "      <td>Kessler</td>\n",
       "      <td>671 Troy Isle Suite 459\\r\\nNew Carriemouth, OK...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>'German Shepherd'</td>\n",
       "      <td>Cristopher</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.821139</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>4.692451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>596</td>\n",
       "      <td>Ethan</td>\n",
       "      <td>Schuppe</td>\n",
       "      <td>17224 Koelpin Rest\\r\\nTheresiashire, GA 69914</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>'Bulldog'</td>\n",
       "      <td>Filomena</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.396222</td>\n",
       "      <td>0.306561</td>\n",
       "      <td>5.775798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>597</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Legros</td>\n",
       "      <td>476 Veda View\\r\\nGroverfurt, AK 15766-2282</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91</td>\n",
       "      <td>'Shi-ba-inu'</td>\n",
       "      <td>Herta</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.425255</td>\n",
       "      <td>0.201590</td>\n",
       "      <td>3.474951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>598</td>\n",
       "      <td>Ilene</td>\n",
       "      <td>Dietrich</td>\n",
       "      <td>934 Josianne Inlet\\r\\nLavonnechester, AZ 30057...</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>'Poodle'</td>\n",
       "      <td>Lamont</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>1.512764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>599</td>\n",
       "      <td>Novella</td>\n",
       "      <td>Becker</td>\n",
       "      <td>76281 Germaine Valley\\r\\nBoscobury, DE 99069-3814</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>'Golden Retriever'</td>\n",
       "      <td>Wendy</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.427905</td>\n",
       "      <td>0.757455</td>\n",
       "      <td>5.224393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>600</td>\n",
       "      <td>Rodrick</td>\n",
       "      <td>Pacocha</td>\n",
       "      <td>840 Pfeffer Club\\r\\nEast Amiya, MO 28324</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>'Maltese'</td>\n",
       "      <td>Alia</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.378318</td>\n",
       "      <td>0.289861</td>\n",
       "      <td>3.797761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_id First_Name Last_Name  \\\n",
       "0          1       Jane     Bruen   \n",
       "1          2     Eliseo   Trantow   \n",
       "2          3     Oceane    Walter   \n",
       "3          4       Zack    Marvin   \n",
       "4          5      Marco   Kessler   \n",
       "..       ...        ...       ...   \n",
       "595      596      Ethan   Schuppe   \n",
       "596      597     Austin    Legros   \n",
       "597      598      Ilene  Dietrich   \n",
       "598      599    Novella    Becker   \n",
       "599      600    Rodrick   Pacocha   \n",
       "\n",
       "                                               Address  Age  Gender  \\\n",
       "0    5272 Adela Overpass Suite 982\\r\\nRozellacheste...   28       1   \n",
       "1     2506 Mertz Inlet\\r\\nSouth Ezekielshire, OK 56215   12       1   \n",
       "2    9469 Frank Orchard Apt. 685\\r\\nLake Irmastad, ...   64       1   \n",
       "3        982 Susan Manors\\r\\nPort Amiya, UT 97043-2723   38       1   \n",
       "4    671 Troy Isle Suite 459\\r\\nNew Carriemouth, OK...   28       1   \n",
       "..                                                 ...  ...     ...   \n",
       "595      17224 Koelpin Rest\\r\\nTheresiashire, GA 69914   79       2   \n",
       "596         476 Veda View\\r\\nGroverfurt, AK 15766-2282   80       1   \n",
       "597  934 Josianne Inlet\\r\\nLavonnechester, AZ 30057...   74       1   \n",
       "598  76281 Germaine Valley\\r\\nBoscobury, DE 99069-3814   29       2   \n",
       "599           840 Pfeffer Club\\r\\nEast Amiya, MO 28324   25       1   \n",
       "\n",
       "     Rehabilitation  Pet_intimacy       category_name    Pet_Name  log_count  \\\n",
       "0                 2          0.42           'Maltese'      Barney   0.333333   \n",
       "1                 1          0.12  'Golden Retriever'     Juliana   0.000000   \n",
       "2                 2          0.91           'Bulldog'     Sabrina   0.500000   \n",
       "3                 1          0.86   'German Shepherd'     Yasmine   0.666667   \n",
       "4                 1          0.19   'German Shepherd'  Cristopher   0.250000   \n",
       "..              ...           ...                 ...         ...        ...   \n",
       "595               1          0.82           'Bulldog'    Filomena   0.250000   \n",
       "596               2          0.91        'Shi-ba-inu'       Herta   0.166667   \n",
       "597               2          0.28            'Poodle'      Lamont   0.083333   \n",
       "598               2          0.10  'Golden Retriever'       Wendy   0.500000   \n",
       "599               2          0.76           'Maltese'        Alia   0.333333   \n",
       "\n",
       "     com_count  avg_loading  sum_duration  User_satisfication  \n",
       "0     0.333333     0.526948      0.268787            3.522098  \n",
       "1     0.083333     1.000000      0.003579            3.717647  \n",
       "2     0.166667     0.526618      0.225447            4.005074  \n",
       "3     0.583333     0.550415      0.831412            9.152728  \n",
       "4     0.500000     0.821139      0.045328            4.692451  \n",
       "..         ...          ...           ...                 ...  \n",
       "595   0.333333     0.396222      0.306561            5.775798  \n",
       "596   0.500000     0.425255      0.201590            3.474951  \n",
       "597   0.333333     0.215269      0.004374            1.512764  \n",
       "598   0.166667     0.427905      0.757455            5.224393  \n",
       "599   0.333333     0.378318      0.289861            3.797761  \n",
       "\n",
       "[600 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(root_path, 'data_with_satisfication.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    596.000000\n",
       "mean       4.782320\n",
       "std        1.405241\n",
       "min        1.302399\n",
       "25%        3.783285\n",
       "50%        4.849050\n",
       "75%        5.718694\n",
       "max        9.152728\n",
       "Name: User_satisfication, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"User_satisfication\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loading\n",
      "sum_duration\n",
      "User_satisfication\n"
     ]
    }
   ],
   "source": [
    "for c in data.columns:\n",
    "    if data[c].isnull().values.any():\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1e6f0625e80>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data, x=\"User_satisfication\").set(title=\"User Satisfication Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 15)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"Age\", \"Gender\", \"Rehabilitation\", \"Pet_intimacy\", \"log_count\", \"com_count\", \"avg_loading\", \"sum_duration\"]].values\n",
    "Y = data[[\"User_satisfication\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15350304, 0.        , 0.74832732, ..., 0.24944244, 0.39432989,\n",
       "        0.20114086],\n",
       "       [0.        , 0.        , 0.        , ..., 0.0825405 , 0.99048605,\n",
       "        0.00354448],\n",
       "       [0.39305406, 0.        , 0.58958109, ..., 0.09826351, 0.310484  ,\n",
       "        0.13291947],\n",
       "       ...,\n",
       "       [0.58117198, 0.        , 0.73115185, ..., 0.24371728, 0.15739443,\n",
       "        0.00319788],\n",
       "       [0.12397897, 0.56884468, 0.56884468, ..., 0.09480745, 0.2434115 ,\n",
       "        0.4308744 ],\n",
       "       [0.11637483, 0.        , 0.69824896, ..., 0.23274965, 0.2641602 ,\n",
       "        0.20239503]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_normal = preprocessing.normalize(X_scale)\n",
    "X_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_val, Y_train, Y_test_val = train_test_split(X_normal, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test_val, Y_test_val, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  417 \n",
      "Validation size:  89 \n",
      "Test size:  90\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \", X_train.shape[0], \"\\nValidation size: \", X_val.shape[0], \"\\nTest size: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 20.2260 - mean_squared_error: 20.2260 - val_loss: 20.9441 - val_mean_squared_error: 20.9441\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 19.6321 - mean_squared_error: 19.6321 - val_loss: 20.3798 - val_mean_squared_error: 20.3798\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 19.1054 - mean_squared_error: 19.1054 - val_loss: 19.8634 - val_mean_squared_error: 19.8634\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 18.6115 - mean_squared_error: 18.6115 - val_loss: 19.3651 - val_mean_squared_error: 19.3651\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 18.1317 - mean_squared_error: 18.1317 - val_loss: 18.8857 - val_mean_squared_error: 18.8857\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 17.6830 - mean_squared_error: 17.6830 - val_loss: 18.4583 - val_mean_squared_error: 18.4583\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 17.2996 - mean_squared_error: 17.2996 - val_loss: 18.1133 - val_mean_squared_error: 18.1133\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.9993 - mean_squared_error: 16.9993 - val_loss: 17.8551 - val_mean_squared_error: 17.8551\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.7783 - mean_squared_error: 16.7783 - val_loss: 17.6698 - val_mean_squared_error: 17.6698\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.6209 - mean_squared_error: 16.6209 - val_loss: 17.5387 - val_mean_squared_error: 17.5387\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.5093 - mean_squared_error: 16.5093 - val_loss: 17.4454 - val_mean_squared_error: 17.4454\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.4294 - mean_squared_error: 16.4294 - val_loss: 17.3778 - val_mean_squared_error: 17.3778\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.3711 - mean_squared_error: 16.3711 - val_loss: 17.3278 - val_mean_squared_error: 17.3278\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.3276 - mean_squared_error: 16.3276 - val_loss: 17.2901 - val_mean_squared_error: 17.2901\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.2945 - mean_squared_error: 16.2945 - val_loss: 17.2610 - val_mean_squared_error: 17.2610\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.2688 - mean_squared_error: 16.2688 - val_loss: 17.2382 - val_mean_squared_error: 17.2382\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.2484 - mean_squared_error: 16.2484 - val_loss: 17.2199 - val_mean_squared_error: 17.2199\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.2320 - mean_squared_error: 16.2320 - val_loss: 17.2051 - val_mean_squared_error: 17.2051\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.2186 - mean_squared_error: 16.2186 - val_loss: 17.1928 - val_mean_squared_error: 17.1928\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.2075 - mean_squared_error: 16.2075 - val_loss: 17.1826 - val_mean_squared_error: 17.1826\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1982 - mean_squared_error: 16.1982 - val_loss: 17.1740 - val_mean_squared_error: 17.1740\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1904 - mean_squared_error: 16.1904 - val_loss: 17.1667 - val_mean_squared_error: 17.1667\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1837 - mean_squared_error: 16.1837 - val_loss: 17.1604 - val_mean_squared_error: 17.1604\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1779 - mean_squared_error: 16.1779 - val_loss: 17.1550 - val_mean_squared_error: 17.1550\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1728 - mean_squared_error: 16.1728 - val_loss: 17.1502 - val_mean_squared_error: 17.1502\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1684 - mean_squared_error: 16.1684 - val_loss: 17.1460 - val_mean_squared_error: 17.1460\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1646 - mean_squared_error: 16.1646 - val_loss: 17.1424 - val_mean_squared_error: 17.1424\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1611 - mean_squared_error: 16.1611 - val_loss: 17.1391 - val_mean_squared_error: 17.1391\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1581 - mean_squared_error: 16.1581 - val_loss: 17.1361 - val_mean_squared_error: 17.1361\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1553 - mean_squared_error: 16.1553 - val_loss: 17.1335 - val_mean_squared_error: 17.1335\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1529 - mean_squared_error: 16.1529 - val_loss: 17.1311 - val_mean_squared_error: 17.1311\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1506 - mean_squared_error: 16.1506 - val_loss: 17.1290 - val_mean_squared_error: 17.1290\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1486 - mean_squared_error: 16.1486 - val_loss: 17.1270 - val_mean_squared_error: 17.1270\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1468 - mean_squared_error: 16.1468 - val_loss: 17.1252 - val_mean_squared_error: 17.1252\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1451 - mean_squared_error: 16.1451 - val_loss: 17.1236 - val_mean_squared_error: 17.1236\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1436 - mean_squared_error: 16.1436 - val_loss: 17.1221 - val_mean_squared_error: 17.1221\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1422 - mean_squared_error: 16.1422 - val_loss: 17.1207 - val_mean_squared_error: 17.1207\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1409 - mean_squared_error: 16.1409 - val_loss: 17.1195 - val_mean_squared_error: 17.1195\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1397 - mean_squared_error: 16.1397 - val_loss: 17.1183 - val_mean_squared_error: 17.1183\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1385 - mean_squared_error: 16.1385 - val_loss: 17.1172 - val_mean_squared_error: 17.1172\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1375 - mean_squared_error: 16.1375 - val_loss: 17.1162 - val_mean_squared_error: 17.1162\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1365 - mean_squared_error: 16.1365 - val_loss: 17.1152 - val_mean_squared_error: 17.1152\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1357 - mean_squared_error: 16.1357 - val_loss: 17.1143 - val_mean_squared_error: 17.1143\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 16.1348 - mean_squared_error: 16.1348 - val_loss: 17.1135 - val_mean_squared_error: 17.1135\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1340 - mean_squared_error: 16.1340 - val_loss: 17.1127 - val_mean_squared_error: 17.1127\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1333 - mean_squared_error: 16.1333 - val_loss: 17.1120 - val_mean_squared_error: 17.1120\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1326 - mean_squared_error: 16.1326 - val_loss: 17.1113 - val_mean_squared_error: 17.1113\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1319 - mean_squared_error: 16.1319 - val_loss: 17.1107 - val_mean_squared_error: 17.1107\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1313 - mean_squared_error: 16.1313 - val_loss: 17.1101 - val_mean_squared_error: 17.1101\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1308 - mean_squared_error: 16.1308 - val_loss: 17.1095 - val_mean_squared_error: 17.1095\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1302 - mean_squared_error: 16.1302 - val_loss: 17.1090 - val_mean_squared_error: 17.1090\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1297 - mean_squared_error: 16.1297 - val_loss: 17.1084 - val_mean_squared_error: 17.1084\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1292 - mean_squared_error: 16.1292 - val_loss: 17.1080 - val_mean_squared_error: 17.1080\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1287 - mean_squared_error: 16.1287 - val_loss: 17.1075 - val_mean_squared_error: 17.1075\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1283 - mean_squared_error: 16.1283 - val_loss: 17.1071 - val_mean_squared_error: 17.1071\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1279 - mean_squared_error: 16.1279 - val_loss: 17.1066 - val_mean_squared_error: 17.1066\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1275 - mean_squared_error: 16.1275 - val_loss: 17.1062 - val_mean_squared_error: 17.1062\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1271 - mean_squared_error: 16.1271 - val_loss: 17.1059 - val_mean_squared_error: 17.1059\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1267 - mean_squared_error: 16.1267 - val_loss: 17.1055 - val_mean_squared_error: 17.1055\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1264 - mean_squared_error: 16.1264 - val_loss: 17.1052 - val_mean_squared_error: 17.1052\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1261 - mean_squared_error: 16.1261 - val_loss: 17.1048 - val_mean_squared_error: 17.1048\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1257 - mean_squared_error: 16.1257 - val_loss: 17.1045 - val_mean_squared_error: 17.1045\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1254 - mean_squared_error: 16.1254 - val_loss: 17.1042 - val_mean_squared_error: 17.1042\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1251 - mean_squared_error: 16.1251 - val_loss: 17.1039 - val_mean_squared_error: 17.1039\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1249 - mean_squared_error: 16.1249 - val_loss: 17.1036 - val_mean_squared_error: 17.1036\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1246 - mean_squared_error: 16.1246 - val_loss: 17.1034 - val_mean_squared_error: 17.1034\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1243 - mean_squared_error: 16.1243 - val_loss: 17.1031 - val_mean_squared_error: 17.1031\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1241 - mean_squared_error: 16.1241 - val_loss: 17.1029 - val_mean_squared_error: 17.1029\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1239 - mean_squared_error: 16.1239 - val_loss: 17.1026 - val_mean_squared_error: 17.1026\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1236 - mean_squared_error: 16.1236 - val_loss: 17.1024 - val_mean_squared_error: 17.1024\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1234 - mean_squared_error: 16.1234 - val_loss: 17.1022 - val_mean_squared_error: 17.1022\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1232 - mean_squared_error: 16.1232 - val_loss: 17.1020 - val_mean_squared_error: 17.1020\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1230 - mean_squared_error: 16.1230 - val_loss: 17.1018 - val_mean_squared_error: 17.1018\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1228 - mean_squared_error: 16.1228 - val_loss: 17.1016 - val_mean_squared_error: 17.1016\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1226 - mean_squared_error: 16.1226 - val_loss: 17.1014 - val_mean_squared_error: 17.1014\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 16.1224 - mean_squared_error: 16.1224 - val_loss: 17.1012 - val_mean_squared_error: 17.1012\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1223 - mean_squared_error: 16.1223 - val_loss: 17.1010 - val_mean_squared_error: 17.1010\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1221 - mean_squared_error: 16.1221 - val_loss: 17.1008 - val_mean_squared_error: 17.1008\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1219 - mean_squared_error: 16.1219 - val_loss: 17.1007 - val_mean_squared_error: 17.1007\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1218 - mean_squared_error: 16.1218 - val_loss: 17.1005 - val_mean_squared_error: 17.1005\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1216 - mean_squared_error: 16.1216 - val_loss: 17.1004 - val_mean_squared_error: 17.1004\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1215 - mean_squared_error: 16.1215 - val_loss: 17.1002 - val_mean_squared_error: 17.1002\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1213 - mean_squared_error: 16.1213 - val_loss: 17.1001 - val_mean_squared_error: 17.1001\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1212 - mean_squared_error: 16.1212 - val_loss: 17.0999 - val_mean_squared_error: 17.0999\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1210 - mean_squared_error: 16.1210 - val_loss: 17.0998 - val_mean_squared_error: 17.0998\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1209 - mean_squared_error: 16.1209 - val_loss: 17.0997 - val_mean_squared_error: 17.0997\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1208 - mean_squared_error: 16.1208 - val_loss: 17.0995 - val_mean_squared_error: 17.0995\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1207 - mean_squared_error: 16.1207 - val_loss: 17.0994 - val_mean_squared_error: 17.0994\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1205 - mean_squared_error: 16.1205 - val_loss: 17.0993 - val_mean_squared_error: 17.0993\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1204 - mean_squared_error: 16.1204 - val_loss: 17.0992 - val_mean_squared_error: 17.0992\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1203 - mean_squared_error: 16.1203 - val_loss: 17.0990 - val_mean_squared_error: 17.0990\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1202 - mean_squared_error: 16.1202 - val_loss: 17.0989 - val_mean_squared_error: 17.0989\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1201 - mean_squared_error: 16.1201 - val_loss: 17.0988 - val_mean_squared_error: 17.0988\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1200 - mean_squared_error: 16.1200 - val_loss: 17.0987 - val_mean_squared_error: 17.0987\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1199 - mean_squared_error: 16.1199 - val_loss: 17.0986 - val_mean_squared_error: 17.0986\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1198 - mean_squared_error: 16.1198 - val_loss: 17.0985 - val_mean_squared_error: 17.0985\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1197 - mean_squared_error: 16.1197 - val_loss: 17.0984 - val_mean_squared_error: 17.0984\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1196 - mean_squared_error: 16.1196 - val_loss: 17.0983 - val_mean_squared_error: 17.0983\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1195 - mean_squared_error: 16.1195 - val_loss: 17.0982 - val_mean_squared_error: 17.0982\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1194 - mean_squared_error: 16.1194 - val_loss: 17.0981 - val_mean_squared_error: 17.0981\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1193 - mean_squared_error: 16.1193 - val_loss: 17.0981 - val_mean_squared_error: 17.0981\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1192 - mean_squared_error: 16.1192 - val_loss: 17.0980 - val_mean_squared_error: 17.0980\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1192 - mean_squared_error: 16.1192 - val_loss: 17.0979 - val_mean_squared_error: 17.0979\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1191 - mean_squared_error: 16.1191 - val_loss: 17.0978 - val_mean_squared_error: 17.0978\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1190 - mean_squared_error: 16.1190 - val_loss: 17.0977 - val_mean_squared_error: 17.0977\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1189 - mean_squared_error: 16.1189 - val_loss: 17.0976 - val_mean_squared_error: 17.0976\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1189 - mean_squared_error: 16.1189 - val_loss: 17.0976 - val_mean_squared_error: 17.0976\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1188 - mean_squared_error: 16.1188 - val_loss: 17.0975 - val_mean_squared_error: 17.0975\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1187 - mean_squared_error: 16.1187 - val_loss: 17.0974 - val_mean_squared_error: 17.0974\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1186 - mean_squared_error: 16.1186 - val_loss: 17.0974 - val_mean_squared_error: 17.0974\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1186 - mean_squared_error: 16.1186 - val_loss: 17.0973 - val_mean_squared_error: 17.0973\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1185 - mean_squared_error: 16.1185 - val_loss: 17.0972 - val_mean_squared_error: 17.0972\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1184 - mean_squared_error: 16.1184 - val_loss: 17.0972 - val_mean_squared_error: 17.0972\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1184 - mean_squared_error: 16.1184 - val_loss: 17.0971 - val_mean_squared_error: 17.0971\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1183 - mean_squared_error: 16.1183 - val_loss: 17.0970 - val_mean_squared_error: 17.0970\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1183 - mean_squared_error: 16.1183 - val_loss: 17.0970 - val_mean_squared_error: 17.0970\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1182 - mean_squared_error: 16.1182 - val_loss: 17.0969 - val_mean_squared_error: 17.0969\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1181 - mean_squared_error: 16.1181 - val_loss: 17.0968 - val_mean_squared_error: 17.0968\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1181 - mean_squared_error: 16.1181 - val_loss: 17.0968 - val_mean_squared_error: 17.0968\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1180 - mean_squared_error: 16.1180 - val_loss: 17.0967 - val_mean_squared_error: 17.0967\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1180 - mean_squared_error: 16.1180 - val_loss: 17.0967 - val_mean_squared_error: 17.0967\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1179 - mean_squared_error: 16.1179 - val_loss: 17.0966 - val_mean_squared_error: 17.0966\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1179 - mean_squared_error: 16.1179 - val_loss: 17.0966 - val_mean_squared_error: 17.0966\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1178 - mean_squared_error: 16.1178 - val_loss: 17.0965 - val_mean_squared_error: 17.0965\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1178 - mean_squared_error: 16.1178 - val_loss: 17.0965 - val_mean_squared_error: 17.0965\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1177 - mean_squared_error: 16.1177 - val_loss: 17.0964 - val_mean_squared_error: 17.0964\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1177 - mean_squared_error: 16.1177 - val_loss: 17.0964 - val_mean_squared_error: 17.0964\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.1176 - mean_squared_error: 16.1176 - val_loss: 17.0963 - val_mean_squared_error: 17.0963\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1176 - mean_squared_error: 16.1176 - val_loss: 17.0963 - val_mean_squared_error: 17.0963\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1175 - mean_squared_error: 16.1175 - val_loss: 17.0962 - val_mean_squared_error: 17.0962\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1175 - mean_squared_error: 16.1175 - val_loss: 17.0962 - val_mean_squared_error: 17.0962\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1174 - mean_squared_error: 16.1174 - val_loss: 17.0961 - val_mean_squared_error: 17.0961\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.1174 - mean_squared_error: 16.1174 - val_loss: 17.0961 - val_mean_squared_error: 17.0961\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1173 - mean_squared_error: 16.1173 - val_loss: 17.0960 - val_mean_squared_error: 17.0960\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1173 - mean_squared_error: 16.1173 - val_loss: 17.0960 - val_mean_squared_error: 17.0960\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1173 - mean_squared_error: 16.1173 - val_loss: 17.0960 - val_mean_squared_error: 17.0960\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1172 - mean_squared_error: 16.1172 - val_loss: 17.0959 - val_mean_squared_error: 17.0959\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1172 - mean_squared_error: 16.1172 - val_loss: 17.0959 - val_mean_squared_error: 17.0959\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1171 - mean_squared_error: 16.1171 - val_loss: 17.0958 - val_mean_squared_error: 17.0958\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1171 - mean_squared_error: 16.1171 - val_loss: 17.0958 - val_mean_squared_error: 17.0958\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1171 - mean_squared_error: 16.1171 - val_loss: 17.0958 - val_mean_squared_error: 17.0958\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.1170 - mean_squared_error: 16.1170 - val_loss: 17.0957 - val_mean_squared_error: 17.0957\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1170 - mean_squared_error: 16.1170 - val_loss: 17.0957 - val_mean_squared_error: 17.0957\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1170 - mean_squared_error: 16.1170 - val_loss: 17.0956 - val_mean_squared_error: 17.0956\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1169 - mean_squared_error: 16.1169 - val_loss: 17.0956 - val_mean_squared_error: 17.0956\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1169 - mean_squared_error: 16.1169 - val_loss: 17.0956 - val_mean_squared_error: 17.0956\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.1169 - mean_squared_error: 16.1169 - val_loss: 17.0955 - val_mean_squared_error: 17.0955\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1168 - mean_squared_error: 16.1168 - val_loss: 17.0955 - val_mean_squared_error: 17.0955\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1168 - mean_squared_error: 16.1168 - val_loss: 17.0955 - val_mean_squared_error: 17.0955\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.1168 - mean_squared_error: 16.1168 - val_loss: 17.0954 - val_mean_squared_error: 17.0954\n"
     ]
    }
   ],
   "source": [
    "# There are 8 columns in the X data, meaning we are using 8 features to make predictions\n",
    "# We would build a neural network with two hidden layers of size 32 and output a single predicted value of y(the satisfication level)\n",
    "# website to draw nn archetecture: http://alexlenail.me/NN-SVG/index.html\n",
    "nn_model = Sequential([\n",
    "    Dense(32, activation=\"relu\", input_shape=(8,)),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "nn_model.compile(optimizer='sgd',\n",
    "                loss=\"mse\",\n",
    "                metrics=['mean_squared_error'])\n",
    "Y_pred = nn_model.fit(X_train, Y_train, batch_size=70, epochs=150, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 16.2356 - mean_squared_error: 16.2356\n"
     ]
    }
   ],
   "source": [
    "score = nn_model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# == Above are the code for Neural Network, below were previously wrote =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "class NN():\n",
    "    def __init__(self, input_n, layers=[256,128], output_n, lr, iterations):\n",
    "        self.input_layer = input_n\n",
    "        self.output_layer = output_n\n",
    "        self.fc1 = nn.Linear(self.input_layer, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], self.output_layer)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "class NN_train_test():\n",
    "    def __init__(self, input_n, layers, output_n, lrï¼Œ iterations, num_epochs):\n",
    "        self.model = NN(input_n=input_n, layers=layers, output_n=output_n, lr=lr, iterations=iterations)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(),lr=lr)\n",
    "        self.num_epochs = num_epochs\n",
    "    def train(X, y):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            correct = 0\n",
    "            l = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                data = X.iloc[i, :]\n",
    "                result = y.iloc[i, :]\n",
    "                prediction = self.model(data)\n",
    "                loss = self.criterion(prediction, result)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predictions = prediction.max(dim=1)\n",
    "                correct += torch.eq(predictions, result).sum().item()\n",
    "                l += result.shape[0]\n",
    "            accuracy = correct / l\n",
    "            print(\"Epoch: {}, Accuracy: {}\".format(epoch, accuracy))\n",
    "\n",
    "    def test(X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpKEc4OTYxRo"
   },
   "outputs": [],
   "source": [
    "# Logistic Model\n",
    "input = data.loc[:, 'Have diseases':\"Recovery\"]\n",
    "target = data[[\"Recovery\"]]\n",
    "\n",
    "X, y = input, target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieSUPdkMRXd9"
   },
   "outputs": [],
   "source": [
    "iterations_n = 1000\n",
    "learning_rate = 0.01\n",
    "num_feature = len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yps8b_Gqtx17"
   },
   "outputs": [],
   "source": [
    "class PytorchLRModel(nn.Module):\n",
    "    def __init__(self, num_feature):\n",
    "        super(PytorchLRModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_feature, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x[:,1]\n",
    "\n",
    "clf = PytorchLRModel(num_feature)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Y05PFe8qXEE",
    "outputId": "d664d87b-84a0-4a29-bd8d-da72202086be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 52.380950927734375\n",
      "Iteration 100, Loss: 52.380950927734375\n",
      "Iteration 200, Loss: 52.380950927734375\n",
      "Iteration 300, Loss: 52.380950927734375\n",
      "Iteration 400, Loss: 52.380950927734375\n",
      "Iteration 500, Loss: 52.380950927734375\n",
      "Iteration 600, Loss: 52.380950927734375\n",
      "Iteration 700, Loss: 52.380950927734375\n",
      "Iteration 800, Loss: 52.380950927734375\n",
      "Iteration 900, Loss: 52.380950927734375\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(clf.parameters(), lr=learning_rate)\n",
    "input = Variable(torch.Tensor(X_train.values))\n",
    "target = Variable(torch.Tensor(y_train.values)).long()\n",
    "\n",
    "clf.train()\n",
    "for iter_ in range(iterations_n):\n",
    "  optimizer.zero_grad()\n",
    "  scores = clf(input)\n",
    "  loss = criterion(scores.unsqueeze(1), target.float())\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if iter_ % 100 == 0:\n",
    "    print('Iteration {}, Loss: {}'.format(iter_, loss.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfgVPnT3vp5a",
    "outputId": "366dbeb4-8f45-445e-b22b-a5fb348a8db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([8, 1])\n",
      "Accuracy:  5.0\n"
     ]
    }
   ],
   "source": [
    "clf.eval()\n",
    "target = Variable(torch.Tensor(y_test.values)).long()\n",
    "y_hat = clf(Variable(torch.Tensor(X_test.values)))\n",
    "predictions = (y_hat >= 0.5).float()\n",
    "print(predictions)\n",
    "print(target.shape)\n",
    "accuracy = torch.eq(predictions, target).sum().item() / target.size()[0]\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RVwIxOyeZiT",
    "outputId": "d09c43ca-3f2a-44f5-bb8b-af7c404d6aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058571500000000006\n",
      "0.2420154953716807\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators = 500, max_features = 'sqrt', max_depth = 8, random_state = 18).fit(X_train, y_train)\n",
    "prediction = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, prediction)\n",
    "rmse = mse**.5\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztcW4YAJedP3"
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "class NN():\n",
    "    def __init__(self, input_n, layers=[256,128], output_n, lr, iterations):\n",
    "        self.input_layer = input_n\n",
    "        self.output_layer = output_n\n",
    "        self.fc1 = nn.Linear(self.input_layer, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], self.output_layer)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "class NN_train_test():\n",
    "    def __init__(self, input_n, layers, output_n, lrï¼Œ iterations, num_epochs):\n",
    "        self.model = NN(input_n=input_n, layers=layers, output_n=output_n, lr=lr, iterations=iterations)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(),lr=lr)\n",
    "        self.num_epochs = num_epochs\n",
    "    def train(X, y):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            correct = 0\n",
    "            l = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                data = X.iloc[i, :]\n",
    "                result = y.iloc[i, :]\n",
    "                prediction = self.model(data)\n",
    "                loss = self.criterion(prediction, result)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predictions = prediction.max(dim=1)\n",
    "                correct += torch.eq(predictions, result).sum().item()\n",
    "                l += result.shape[0]\n",
    "            accuracy = correct / l\n",
    "            print(\"Epoch: {}, Accuracy: {}\".format(epoch, accuracy))\n",
    "\n",
    "    def test(X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWKsGGTtZwgh"
   },
   "outputs": [],
   "source": [
    "# RNN\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
